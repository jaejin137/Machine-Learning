{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8121510b-4b57-4d3e-bb6d-9b4c5af77c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b2e255f-ff1a-4192-91a7-3c48a976e236",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1/(1+e**-z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ccea69d-04e0-475f-b563-d245169ba0f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5000249999999792"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid(.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "651ca3e4-dc9d-48ef-9be2-8b76848319f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ccbf21b3-024a-4ffa-ab6b-bb718ce632c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2689414213699951"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f6ca6d8-c608-4353-807e-8ab78aa1ee16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.7200759760208555e-44"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid(-100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6fe5b88-aeda-489e-adbe-c49ef92d8592",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "314f952c-c4eb-4afb-9ba5-843cc930a5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = np.arange(0,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e5bb24fc-57b1-426c-b3fa-d3bea251ed51",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib.plot'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib.plot'"
     ]
    }
   ],
   "source": [
    "from matplotlib.plot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52536d6d-e28a-49e7-a350-d5cb5b19e398",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f444986-b6fe-49dc-8665-e7414b7bfdb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import SGD\n",
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0637fc09-1fa9-4445-9c08-60d21c90f669",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11490434/11490434 [==============================] - 15s 1us/step\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0bd3ce4e-e0c8-4b64-9f96-f4f09a8907c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "11137533-9968-46a4-ae87-951ae8c2412e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "73f4c4b3-e528-4c27-b9de-918c64c7307f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9c076623-160d-48f6-bd50-ce168cedb46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(60000, 28*28).astype('float32') / 255\n",
    "X_test = X_test.reshape(10000, 28*28).astype('float32') / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "70aba9cc-5fc2-4621-ad6e-fedd3e232754",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.01176471, 0.07058824, 0.07058824,\n",
       "       0.07058824, 0.49411765, 0.53333336, 0.6862745 , 0.10196079,\n",
       "       0.6509804 , 1.        , 0.96862745, 0.49803922, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.11764706, 0.14117648, 0.36862746, 0.6039216 ,\n",
       "       0.6666667 , 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.99215686, 0.88235295, 0.6745098 , 0.99215686, 0.9490196 ,\n",
       "       0.7647059 , 0.2509804 , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.19215687, 0.93333334,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.9843137 , 0.3647059 ,\n",
       "       0.32156864, 0.32156864, 0.21960784, 0.15294118, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.07058824, 0.85882354, 0.99215686, 0.99215686,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.7764706 , 0.7137255 ,\n",
       "       0.96862745, 0.94509804, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.3137255 , 0.6117647 , 0.41960785, 0.99215686, 0.99215686,\n",
       "       0.8039216 , 0.04313726, 0.        , 0.16862746, 0.6039216 ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.05490196,\n",
       "       0.00392157, 0.6039216 , 0.99215686, 0.3529412 , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.54509807,\n",
       "       0.99215686, 0.74509805, 0.00784314, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.04313726, 0.74509805, 0.99215686,\n",
       "       0.27450982, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.13725491, 0.94509804, 0.88235295, 0.627451  ,\n",
       "       0.42352942, 0.00392157, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.31764707, 0.9411765 , 0.99215686, 0.99215686, 0.46666667,\n",
       "       0.09803922, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.1764706 ,\n",
       "       0.7294118 , 0.99215686, 0.99215686, 0.5882353 , 0.10588235,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.0627451 , 0.3647059 ,\n",
       "       0.9882353 , 0.99215686, 0.73333335, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.9764706 , 0.99215686,\n",
       "       0.9764706 , 0.2509804 , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.18039216, 0.50980395,\n",
       "       0.7176471 , 0.99215686, 0.99215686, 0.8117647 , 0.00784314,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.15294118,\n",
       "       0.5803922 , 0.8980392 , 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.98039216, 0.7137255 , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.09411765, 0.44705883, 0.8666667 , 0.99215686, 0.99215686,\n",
       "       0.99215686, 0.99215686, 0.7882353 , 0.30588236, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.09019608, 0.25882354, 0.8352941 , 0.99215686,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.7764706 , 0.31764707,\n",
       "       0.00784314, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.07058824, 0.67058825, 0.85882354,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.7647059 ,\n",
       "       0.3137255 , 0.03529412, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.21568628, 0.6745098 ,\n",
       "       0.8862745 , 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.95686275, 0.52156866, 0.04313726, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.53333336, 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.83137256, 0.5294118 , 0.5176471 , 0.0627451 , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        ], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c3e53b17-d9b3-4223-8d7e-914f956965a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3d84afce-4260-466b-a86a-ed3926a9d155",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 10\n",
    "y_train = keras.utils.to_categorical(y_train, n_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2cf3bd28-e0fb-4972-877c-e8133769f2d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "79a38968-5700-4ece-9260-da66200225f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-29 10:40:24.736265: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M2 Max\n",
      "2024-02-29 10:40:24.736305: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 96.00 GB\n",
      "2024-02-29 10:40:24.736315: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 36.00 GB\n",
      "2024-02-29 10:40:24.736380: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-02-29 10:40:24.736410: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(64, activation='sigmoid', input_shape=(784,)))\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "511e302b-cddd-4783-9ff4-fbd6184269e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 64)                50240     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 50890 (198.79 KB)\n",
      "Trainable params: 50890 (198.79 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "408417d0-b023-4725-8239-1dc62b4e6386",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='mean_squared_error', optimizer=SGD(learning_rate=0.01), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b226323e-dca5-4b93-8131-e66bf38c8e18",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-29 12:28:30.181722: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-02-29 12:28:30.191069: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node SGD/AssignVariableOp.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469/469 [==============================] - 3s 5ms/step - loss: 0.0917 - accuracy: 0.1011 - val_loss: 0.0910 - val_accuracy: 0.1103\n",
      "Epoch 2/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0906 - accuracy: 0.1297 - val_loss: 0.0903 - val_accuracy: 0.1512\n",
      "Epoch 3/200\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 0.0900 - accuracy: 0.1803 - val_loss: 0.0897 - val_accuracy: 0.2027\n",
      "Epoch 4/200\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0895 - accuracy: 0.2211 - val_loss: 0.0892 - val_accuracy: 0.2393\n",
      "Epoch 5/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0890 - accuracy: 0.2539 - val_loss: 0.0888 - val_accuracy: 0.2707\n",
      "Epoch 6/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0887 - accuracy: 0.2882 - val_loss: 0.0884 - val_accuracy: 0.3113\n",
      "Epoch 7/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0883 - accuracy: 0.3259 - val_loss: 0.0881 - val_accuracy: 0.3500\n",
      "Epoch 8/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0879 - accuracy: 0.3643 - val_loss: 0.0877 - val_accuracy: 0.3853\n",
      "Epoch 9/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0876 - accuracy: 0.3851 - val_loss: 0.0874 - val_accuracy: 0.3935\n",
      "Epoch 10/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0872 - accuracy: 0.3878 - val_loss: 0.0870 - val_accuracy: 0.3930\n",
      "Epoch 11/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0869 - accuracy: 0.3882 - val_loss: 0.0867 - val_accuracy: 0.3934\n",
      "Epoch 12/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0866 - accuracy: 0.3858 - val_loss: 0.0863 - val_accuracy: 0.3925\n",
      "Epoch 13/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0862 - accuracy: 0.3848 - val_loss: 0.0860 - val_accuracy: 0.3918\n",
      "Epoch 14/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0859 - accuracy: 0.3859 - val_loss: 0.0856 - val_accuracy: 0.3907\n",
      "Epoch 15/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0855 - accuracy: 0.3861 - val_loss: 0.0852 - val_accuracy: 0.3898\n",
      "Epoch 16/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0852 - accuracy: 0.3853 - val_loss: 0.0849 - val_accuracy: 0.3900\n",
      "Epoch 17/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0848 - accuracy: 0.3867 - val_loss: 0.0845 - val_accuracy: 0.3898\n",
      "Epoch 18/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0844 - accuracy: 0.3879 - val_loss: 0.0841 - val_accuracy: 0.3903\n",
      "Epoch 19/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0840 - accuracy: 0.3894 - val_loss: 0.0837 - val_accuracy: 0.3909\n",
      "Epoch 20/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0836 - accuracy: 0.3906 - val_loss: 0.0833 - val_accuracy: 0.3913\n",
      "Epoch 21/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0832 - accuracy: 0.3916 - val_loss: 0.0829 - val_accuracy: 0.3935\n",
      "Epoch 22/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0828 - accuracy: 0.3934 - val_loss: 0.0824 - val_accuracy: 0.3959\n",
      "Epoch 23/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0824 - accuracy: 0.3952 - val_loss: 0.0820 - val_accuracy: 0.3981\n",
      "Epoch 24/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0819 - accuracy: 0.3978 - val_loss: 0.0816 - val_accuracy: 0.4008\n",
      "Epoch 25/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0815 - accuracy: 0.4010 - val_loss: 0.0811 - val_accuracy: 0.4033\n",
      "Epoch 26/200\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 0.0810 - accuracy: 0.4038 - val_loss: 0.0806 - val_accuracy: 0.4067\n",
      "Epoch 27/200\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0806 - accuracy: 0.4069 - val_loss: 0.0802 - val_accuracy: 0.4100\n",
      "Epoch 28/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0801 - accuracy: 0.4109 - val_loss: 0.0797 - val_accuracy: 0.4133\n",
      "Epoch 29/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0796 - accuracy: 0.4146 - val_loss: 0.0792 - val_accuracy: 0.4164\n",
      "Epoch 30/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0792 - accuracy: 0.4192 - val_loss: 0.0787 - val_accuracy: 0.4204\n",
      "Epoch 31/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0787 - accuracy: 0.4236 - val_loss: 0.0782 - val_accuracy: 0.4244\n",
      "Epoch 32/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0782 - accuracy: 0.4289 - val_loss: 0.0777 - val_accuracy: 0.4297\n",
      "Epoch 33/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0777 - accuracy: 0.4338 - val_loss: 0.0772 - val_accuracy: 0.4339\n",
      "Epoch 34/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0772 - accuracy: 0.4381 - val_loss: 0.0767 - val_accuracy: 0.4392\n",
      "Epoch 35/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0767 - accuracy: 0.4430 - val_loss: 0.0762 - val_accuracy: 0.4442\n",
      "Epoch 36/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0762 - accuracy: 0.4475 - val_loss: 0.0757 - val_accuracy: 0.4496\n",
      "Epoch 37/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0757 - accuracy: 0.4530 - val_loss: 0.0752 - val_accuracy: 0.4560\n",
      "Epoch 38/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0752 - accuracy: 0.4587 - val_loss: 0.0747 - val_accuracy: 0.4619\n",
      "Epoch 39/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0747 - accuracy: 0.4651 - val_loss: 0.0742 - val_accuracy: 0.4659\n",
      "Epoch 40/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0741 - accuracy: 0.4696 - val_loss: 0.0736 - val_accuracy: 0.4713\n",
      "Epoch 41/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0736 - accuracy: 0.4750 - val_loss: 0.0731 - val_accuracy: 0.4768\n",
      "Epoch 42/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0731 - accuracy: 0.4805 - val_loss: 0.0726 - val_accuracy: 0.4808\n",
      "Epoch 43/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0726 - accuracy: 0.4861 - val_loss: 0.0721 - val_accuracy: 0.4862\n",
      "Epoch 44/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0721 - accuracy: 0.4915 - val_loss: 0.0716 - val_accuracy: 0.4909\n",
      "Epoch 45/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0716 - accuracy: 0.4969 - val_loss: 0.0711 - val_accuracy: 0.4945\n",
      "Epoch 46/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0711 - accuracy: 0.5011 - val_loss: 0.0706 - val_accuracy: 0.4992\n",
      "Epoch 47/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0706 - accuracy: 0.5056 - val_loss: 0.0700 - val_accuracy: 0.5034\n",
      "Epoch 48/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0700 - accuracy: 0.5100 - val_loss: 0.0695 - val_accuracy: 0.5082\n",
      "Epoch 49/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0695 - accuracy: 0.5135 - val_loss: 0.0690 - val_accuracy: 0.5133\n",
      "Epoch 50/200\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0690 - accuracy: 0.5167 - val_loss: 0.0685 - val_accuracy: 0.5170\n",
      "Epoch 51/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0685 - accuracy: 0.5200 - val_loss: 0.0680 - val_accuracy: 0.5194\n",
      "Epoch 52/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0680 - accuracy: 0.5231 - val_loss: 0.0675 - val_accuracy: 0.5235\n",
      "Epoch 53/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0675 - accuracy: 0.5269 - val_loss: 0.0670 - val_accuracy: 0.5275\n",
      "Epoch 54/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0670 - accuracy: 0.5299 - val_loss: 0.0665 - val_accuracy: 0.5320\n",
      "Epoch 55/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0665 - accuracy: 0.5332 - val_loss: 0.0660 - val_accuracy: 0.5351\n",
      "Epoch 56/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0661 - accuracy: 0.5370 - val_loss: 0.0655 - val_accuracy: 0.5380\n",
      "Epoch 57/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0656 - accuracy: 0.5403 - val_loss: 0.0650 - val_accuracy: 0.5416\n",
      "Epoch 58/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0651 - accuracy: 0.5436 - val_loss: 0.0645 - val_accuracy: 0.5467\n",
      "Epoch 59/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0646 - accuracy: 0.5474 - val_loss: 0.0641 - val_accuracy: 0.5505\n",
      "Epoch 60/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0641 - accuracy: 0.5510 - val_loss: 0.0636 - val_accuracy: 0.5551\n",
      "Epoch 61/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0637 - accuracy: 0.5544 - val_loss: 0.0631 - val_accuracy: 0.5583\n",
      "Epoch 62/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0632 - accuracy: 0.5584 - val_loss: 0.0626 - val_accuracy: 0.5620\n",
      "Epoch 63/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0627 - accuracy: 0.5626 - val_loss: 0.0622 - val_accuracy: 0.5664\n",
      "Epoch 64/200\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 0.0623 - accuracy: 0.5661 - val_loss: 0.0617 - val_accuracy: 0.5705\n",
      "Epoch 65/200\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 0.0618 - accuracy: 0.5706 - val_loss: 0.0613 - val_accuracy: 0.5747\n",
      "Epoch 66/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0614 - accuracy: 0.5752 - val_loss: 0.0608 - val_accuracy: 0.5796\n",
      "Epoch 67/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0609 - accuracy: 0.5792 - val_loss: 0.0604 - val_accuracy: 0.5853\n",
      "Epoch 68/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0605 - accuracy: 0.5836 - val_loss: 0.0599 - val_accuracy: 0.5906\n",
      "Epoch 69/200\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0601 - accuracy: 0.5884 - val_loss: 0.0595 - val_accuracy: 0.5960\n",
      "Epoch 70/200\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0596 - accuracy: 0.5934 - val_loss: 0.0590 - val_accuracy: 0.6019\n",
      "Epoch 71/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0592 - accuracy: 0.5981 - val_loss: 0.0586 - val_accuracy: 0.6080\n",
      "Epoch 72/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0588 - accuracy: 0.6036 - val_loss: 0.0582 - val_accuracy: 0.6144\n",
      "Epoch 73/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0584 - accuracy: 0.6083 - val_loss: 0.0578 - val_accuracy: 0.6198\n",
      "Epoch 74/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0580 - accuracy: 0.6138 - val_loss: 0.0573 - val_accuracy: 0.6248\n",
      "Epoch 75/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0575 - accuracy: 0.6188 - val_loss: 0.0569 - val_accuracy: 0.6301\n",
      "Epoch 76/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0571 - accuracy: 0.6239 - val_loss: 0.0565 - val_accuracy: 0.6358\n",
      "Epoch 77/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0567 - accuracy: 0.6288 - val_loss: 0.0561 - val_accuracy: 0.6410\n",
      "Epoch 78/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0563 - accuracy: 0.6343 - val_loss: 0.0557 - val_accuracy: 0.6460\n",
      "Epoch 79/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0559 - accuracy: 0.6392 - val_loss: 0.0553 - val_accuracy: 0.6516\n",
      "Epoch 80/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0556 - accuracy: 0.6439 - val_loss: 0.0549 - val_accuracy: 0.6566\n",
      "Epoch 81/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0552 - accuracy: 0.6493 - val_loss: 0.0545 - val_accuracy: 0.6623\n",
      "Epoch 82/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0548 - accuracy: 0.6540 - val_loss: 0.0542 - val_accuracy: 0.6671\n",
      "Epoch 83/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0544 - accuracy: 0.6586 - val_loss: 0.0538 - val_accuracy: 0.6720\n",
      "Epoch 84/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0540 - accuracy: 0.6632 - val_loss: 0.0534 - val_accuracy: 0.6772\n",
      "Epoch 85/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0537 - accuracy: 0.6674 - val_loss: 0.0530 - val_accuracy: 0.6820\n",
      "Epoch 86/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0533 - accuracy: 0.6717 - val_loss: 0.0526 - val_accuracy: 0.6859\n",
      "Epoch 87/200\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 0.0529 - accuracy: 0.6754 - val_loss: 0.0523 - val_accuracy: 0.6913\n",
      "Epoch 88/200\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 0.0526 - accuracy: 0.6800 - val_loss: 0.0519 - val_accuracy: 0.6948\n",
      "Epoch 89/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0522 - accuracy: 0.6843 - val_loss: 0.0516 - val_accuracy: 0.6996\n",
      "Epoch 90/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0519 - accuracy: 0.6883 - val_loss: 0.0512 - val_accuracy: 0.7028\n",
      "Epoch 91/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0515 - accuracy: 0.6919 - val_loss: 0.0508 - val_accuracy: 0.7063\n",
      "Epoch 92/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0512 - accuracy: 0.6955 - val_loss: 0.0505 - val_accuracy: 0.7101\n",
      "Epoch 93/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0508 - accuracy: 0.6998 - val_loss: 0.0501 - val_accuracy: 0.7129\n",
      "Epoch 94/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0505 - accuracy: 0.7030 - val_loss: 0.0498 - val_accuracy: 0.7181\n",
      "Epoch 95/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0502 - accuracy: 0.7062 - val_loss: 0.0495 - val_accuracy: 0.7226\n",
      "Epoch 96/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0498 - accuracy: 0.7096 - val_loss: 0.0491 - val_accuracy: 0.7252\n",
      "Epoch 97/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0495 - accuracy: 0.7137 - val_loss: 0.0488 - val_accuracy: 0.7280\n",
      "Epoch 98/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0492 - accuracy: 0.7164 - val_loss: 0.0485 - val_accuracy: 0.7325\n",
      "Epoch 99/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0489 - accuracy: 0.7198 - val_loss: 0.0481 - val_accuracy: 0.7354\n",
      "Epoch 100/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0485 - accuracy: 0.7227 - val_loss: 0.0478 - val_accuracy: 0.7383\n",
      "Epoch 101/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0482 - accuracy: 0.7257 - val_loss: 0.0475 - val_accuracy: 0.7417\n",
      "Epoch 102/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0479 - accuracy: 0.7289 - val_loss: 0.0472 - val_accuracy: 0.7441\n",
      "Epoch 103/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0476 - accuracy: 0.7321 - val_loss: 0.0469 - val_accuracy: 0.7472\n",
      "Epoch 104/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0473 - accuracy: 0.7348 - val_loss: 0.0465 - val_accuracy: 0.7498\n",
      "Epoch 105/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0470 - accuracy: 0.7375 - val_loss: 0.0462 - val_accuracy: 0.7527\n",
      "Epoch 106/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0467 - accuracy: 0.7393 - val_loss: 0.0459 - val_accuracy: 0.7555\n",
      "Epoch 107/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0464 - accuracy: 0.7429 - val_loss: 0.0456 - val_accuracy: 0.7578\n",
      "Epoch 108/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0461 - accuracy: 0.7448 - val_loss: 0.0453 - val_accuracy: 0.7597\n",
      "Epoch 109/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0458 - accuracy: 0.7470 - val_loss: 0.0450 - val_accuracy: 0.7618\n",
      "Epoch 110/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0455 - accuracy: 0.7498 - val_loss: 0.0447 - val_accuracy: 0.7642\n",
      "Epoch 111/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0452 - accuracy: 0.7523 - val_loss: 0.0444 - val_accuracy: 0.7661\n",
      "Epoch 112/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0449 - accuracy: 0.7544 - val_loss: 0.0441 - val_accuracy: 0.7687\n",
      "Epoch 113/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0446 - accuracy: 0.7567 - val_loss: 0.0439 - val_accuracy: 0.7710\n",
      "Epoch 114/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0444 - accuracy: 0.7590 - val_loss: 0.0436 - val_accuracy: 0.7736\n",
      "Epoch 115/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0441 - accuracy: 0.7612 - val_loss: 0.0433 - val_accuracy: 0.7748\n",
      "Epoch 116/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0438 - accuracy: 0.7636 - val_loss: 0.0430 - val_accuracy: 0.7763\n",
      "Epoch 117/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0435 - accuracy: 0.7655 - val_loss: 0.0427 - val_accuracy: 0.7786\n",
      "Epoch 118/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0432 - accuracy: 0.7676 - val_loss: 0.0424 - val_accuracy: 0.7800\n",
      "Epoch 119/200\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0430 - accuracy: 0.7693 - val_loss: 0.0422 - val_accuracy: 0.7825\n",
      "Epoch 120/200\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 0.0427 - accuracy: 0.7719 - val_loss: 0.0419 - val_accuracy: 0.7847\n",
      "Epoch 121/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0424 - accuracy: 0.7743 - val_loss: 0.0416 - val_accuracy: 0.7864\n",
      "Epoch 122/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0422 - accuracy: 0.7764 - val_loss: 0.0414 - val_accuracy: 0.7890\n",
      "Epoch 123/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0419 - accuracy: 0.7782 - val_loss: 0.0411 - val_accuracy: 0.7920\n",
      "Epoch 124/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0417 - accuracy: 0.7800 - val_loss: 0.0408 - val_accuracy: 0.7939\n",
      "Epoch 125/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0414 - accuracy: 0.7820 - val_loss: 0.0406 - val_accuracy: 0.7960\n",
      "Epoch 126/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0412 - accuracy: 0.7845 - val_loss: 0.0403 - val_accuracy: 0.7969\n",
      "Epoch 127/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0409 - accuracy: 0.7858 - val_loss: 0.0401 - val_accuracy: 0.7984\n",
      "Epoch 128/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0407 - accuracy: 0.7879 - val_loss: 0.0398 - val_accuracy: 0.8001\n",
      "Epoch 129/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0404 - accuracy: 0.7896 - val_loss: 0.0396 - val_accuracy: 0.8020\n",
      "Epoch 130/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0402 - accuracy: 0.7913 - val_loss: 0.0393 - val_accuracy: 0.8035\n",
      "Epoch 131/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0399 - accuracy: 0.7940 - val_loss: 0.0391 - val_accuracy: 0.8063\n",
      "Epoch 132/200\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0397 - accuracy: 0.7960 - val_loss: 0.0388 - val_accuracy: 0.8084\n",
      "Epoch 133/200\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0395 - accuracy: 0.7984 - val_loss: 0.0386 - val_accuracy: 0.8113\n",
      "Epoch 134/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0392 - accuracy: 0.8001 - val_loss: 0.0384 - val_accuracy: 0.8134\n",
      "Epoch 135/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0390 - accuracy: 0.8020 - val_loss: 0.0381 - val_accuracy: 0.8159\n",
      "Epoch 136/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0388 - accuracy: 0.8039 - val_loss: 0.0379 - val_accuracy: 0.8179\n",
      "Epoch 137/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0385 - accuracy: 0.8058 - val_loss: 0.0377 - val_accuracy: 0.8190\n",
      "Epoch 138/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0383 - accuracy: 0.8076 - val_loss: 0.0374 - val_accuracy: 0.8205\n",
      "Epoch 139/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0381 - accuracy: 0.8094 - val_loss: 0.0372 - val_accuracy: 0.8224\n",
      "Epoch 140/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0379 - accuracy: 0.8113 - val_loss: 0.0370 - val_accuracy: 0.8231\n",
      "Epoch 141/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0376 - accuracy: 0.8129 - val_loss: 0.0368 - val_accuracy: 0.8249\n",
      "Epoch 142/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0374 - accuracy: 0.8148 - val_loss: 0.0365 - val_accuracy: 0.8265\n",
      "Epoch 143/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0372 - accuracy: 0.8166 - val_loss: 0.0363 - val_accuracy: 0.8277\n",
      "Epoch 144/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0370 - accuracy: 0.8182 - val_loss: 0.0361 - val_accuracy: 0.8298\n",
      "Epoch 145/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0368 - accuracy: 0.8199 - val_loss: 0.0359 - val_accuracy: 0.8307\n",
      "Epoch 146/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0366 - accuracy: 0.8214 - val_loss: 0.0357 - val_accuracy: 0.8319\n",
      "Epoch 147/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0364 - accuracy: 0.8229 - val_loss: 0.0355 - val_accuracy: 0.8336\n",
      "Epoch 148/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0362 - accuracy: 0.8245 - val_loss: 0.0353 - val_accuracy: 0.8342\n",
      "Epoch 149/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0360 - accuracy: 0.8257 - val_loss: 0.0350 - val_accuracy: 0.8353\n",
      "Epoch 150/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0358 - accuracy: 0.8272 - val_loss: 0.0348 - val_accuracy: 0.8374\n",
      "Epoch 151/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0356 - accuracy: 0.8285 - val_loss: 0.0346 - val_accuracy: 0.8383\n",
      "Epoch 152/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0354 - accuracy: 0.8298 - val_loss: 0.0344 - val_accuracy: 0.8393\n",
      "Epoch 153/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0352 - accuracy: 0.8313 - val_loss: 0.0342 - val_accuracy: 0.8409\n",
      "Epoch 154/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0350 - accuracy: 0.8322 - val_loss: 0.0341 - val_accuracy: 0.8416\n",
      "Epoch 155/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0348 - accuracy: 0.8337 - val_loss: 0.0339 - val_accuracy: 0.8427\n",
      "Epoch 156/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0346 - accuracy: 0.8349 - val_loss: 0.0337 - val_accuracy: 0.8435\n",
      "Epoch 157/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0344 - accuracy: 0.8362 - val_loss: 0.0335 - val_accuracy: 0.8438\n",
      "Epoch 158/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0342 - accuracy: 0.8371 - val_loss: 0.0333 - val_accuracy: 0.8449\n",
      "Epoch 159/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0340 - accuracy: 0.8378 - val_loss: 0.0331 - val_accuracy: 0.8471\n",
      "Epoch 160/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0339 - accuracy: 0.8389 - val_loss: 0.0329 - val_accuracy: 0.8477\n",
      "Epoch 161/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0337 - accuracy: 0.8395 - val_loss: 0.0327 - val_accuracy: 0.8484\n",
      "Epoch 162/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0335 - accuracy: 0.8405 - val_loss: 0.0326 - val_accuracy: 0.8495\n",
      "Epoch 163/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0333 - accuracy: 0.8415 - val_loss: 0.0324 - val_accuracy: 0.8502\n",
      "Epoch 164/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0331 - accuracy: 0.8425 - val_loss: 0.0322 - val_accuracy: 0.8504\n",
      "Epoch 165/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0330 - accuracy: 0.8436 - val_loss: 0.0320 - val_accuracy: 0.8512\n",
      "Epoch 166/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0328 - accuracy: 0.8444 - val_loss: 0.0319 - val_accuracy: 0.8526\n",
      "Epoch 167/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0326 - accuracy: 0.8453 - val_loss: 0.0317 - val_accuracy: 0.8533\n",
      "Epoch 168/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0325 - accuracy: 0.8460 - val_loss: 0.0315 - val_accuracy: 0.8541\n",
      "Epoch 169/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0323 - accuracy: 0.8467 - val_loss: 0.0314 - val_accuracy: 0.8549\n",
      "Epoch 170/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0322 - accuracy: 0.8474 - val_loss: 0.0312 - val_accuracy: 0.8558\n",
      "Epoch 171/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0320 - accuracy: 0.8482 - val_loss: 0.0310 - val_accuracy: 0.8570\n",
      "Epoch 172/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0318 - accuracy: 0.8488 - val_loss: 0.0309 - val_accuracy: 0.8573\n",
      "Epoch 173/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0317 - accuracy: 0.8492 - val_loss: 0.0307 - val_accuracy: 0.8581\n",
      "Epoch 174/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0315 - accuracy: 0.8497 - val_loss: 0.0306 - val_accuracy: 0.8592\n",
      "Epoch 175/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0314 - accuracy: 0.8504 - val_loss: 0.0304 - val_accuracy: 0.8603\n",
      "Epoch 176/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0312 - accuracy: 0.8510 - val_loss: 0.0303 - val_accuracy: 0.8607\n",
      "Epoch 177/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0311 - accuracy: 0.8515 - val_loss: 0.0301 - val_accuracy: 0.8609\n",
      "Epoch 178/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0309 - accuracy: 0.8522 - val_loss: 0.0300 - val_accuracy: 0.8615\n",
      "Epoch 179/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0308 - accuracy: 0.8527 - val_loss: 0.0298 - val_accuracy: 0.8621\n",
      "Epoch 180/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0306 - accuracy: 0.8532 - val_loss: 0.0297 - val_accuracy: 0.8627\n",
      "Epoch 181/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0305 - accuracy: 0.8536 - val_loss: 0.0295 - val_accuracy: 0.8637\n",
      "Epoch 182/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0304 - accuracy: 0.8539 - val_loss: 0.0294 - val_accuracy: 0.8639\n",
      "Epoch 183/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0302 - accuracy: 0.8545 - val_loss: 0.0293 - val_accuracy: 0.8642\n",
      "Epoch 184/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0301 - accuracy: 0.8550 - val_loss: 0.0291 - val_accuracy: 0.8652\n",
      "Epoch 185/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0299 - accuracy: 0.8555 - val_loss: 0.0290 - val_accuracy: 0.8657\n",
      "Epoch 186/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0298 - accuracy: 0.8562 - val_loss: 0.0289 - val_accuracy: 0.8667\n",
      "Epoch 187/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0297 - accuracy: 0.8564 - val_loss: 0.0287 - val_accuracy: 0.8676\n",
      "Epoch 188/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0296 - accuracy: 0.8571 - val_loss: 0.0286 - val_accuracy: 0.8683\n",
      "Epoch 189/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0294 - accuracy: 0.8576 - val_loss: 0.0285 - val_accuracy: 0.8688\n",
      "Epoch 190/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0293 - accuracy: 0.8580 - val_loss: 0.0283 - val_accuracy: 0.8695\n",
      "Epoch 191/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0292 - accuracy: 0.8587 - val_loss: 0.0282 - val_accuracy: 0.8700\n",
      "Epoch 192/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0290 - accuracy: 0.8591 - val_loss: 0.0281 - val_accuracy: 0.8702\n",
      "Epoch 193/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0289 - accuracy: 0.8598 - val_loss: 0.0280 - val_accuracy: 0.8705\n",
      "Epoch 194/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0288 - accuracy: 0.8601 - val_loss: 0.0278 - val_accuracy: 0.8708\n",
      "Epoch 195/200\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0287 - accuracy: 0.8604 - val_loss: 0.0277 - val_accuracy: 0.8710\n",
      "Epoch 196/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0286 - accuracy: 0.8611 - val_loss: 0.0276 - val_accuracy: 0.8712\n",
      "Epoch 197/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0284 - accuracy: 0.8613 - val_loss: 0.0275 - val_accuracy: 0.8716\n",
      "Epoch 198/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0283 - accuracy: 0.8618 - val_loss: 0.0274 - val_accuracy: 0.8715\n",
      "Epoch 199/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0282 - accuracy: 0.8622 - val_loss: 0.0273 - val_accuracy: 0.8717\n",
      "Epoch 200/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0281 - accuracy: 0.8626 - val_loss: 0.0271 - val_accuracy: 0.8716\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2981c17c0>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train,\n",
    "          batch_size=128,\n",
    "          epochs=200,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5ec6a9f9-68eb-4bf9-965b-e662587014f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 15177577700940674400\n",
      "xla_global_id: -1\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "locality {\n",
      "  bus_id: 1\n",
      "}\n",
      "incarnation: 11141494072103307976\n",
      "physical_device_desc: \"device: 0, name: METAL, pci bus id: <undefined>\"\n",
      "xla_global_id: -1\n",
      "]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-29 12:37:06.400423: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-02-29 12:37:06.400487: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "78cedcc2-8e16-4c97-aaae-cf830ceabadb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7e594b21-63b2-484f-9626-b9838d99ce0c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0280 - accuracy: 0.8629 - val_loss: 0.0270 - val_accuracy: 0.8714\n",
      "Epoch 2/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0279 - accuracy: 0.8633 - val_loss: 0.0269 - val_accuracy: 0.8715\n",
      "Epoch 3/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0278 - accuracy: 0.8636 - val_loss: 0.0268 - val_accuracy: 0.8719\n",
      "Epoch 4/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0277 - accuracy: 0.8639 - val_loss: 0.0267 - val_accuracy: 0.8727\n",
      "Epoch 5/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0276 - accuracy: 0.8641 - val_loss: 0.0266 - val_accuracy: 0.8731\n",
      "Epoch 6/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0275 - accuracy: 0.8645 - val_loss: 0.0265 - val_accuracy: 0.8733\n",
      "Epoch 7/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0274 - accuracy: 0.8646 - val_loss: 0.0264 - val_accuracy: 0.8738\n",
      "Epoch 8/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0273 - accuracy: 0.8649 - val_loss: 0.0263 - val_accuracy: 0.8741\n",
      "Epoch 9/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0272 - accuracy: 0.8653 - val_loss: 0.0262 - val_accuracy: 0.8747\n",
      "Epoch 10/200\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 0.0271 - accuracy: 0.8657 - val_loss: 0.0261 - val_accuracy: 0.8749\n",
      "Epoch 11/200\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 0.0270 - accuracy: 0.8660 - val_loss: 0.0260 - val_accuracy: 0.8755\n",
      "Epoch 12/200\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 0.0269 - accuracy: 0.8663 - val_loss: 0.0259 - val_accuracy: 0.8763\n",
      "Epoch 13/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0268 - accuracy: 0.8665 - val_loss: 0.0258 - val_accuracy: 0.8764\n",
      "Epoch 14/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0267 - accuracy: 0.8668 - val_loss: 0.0257 - val_accuracy: 0.8767\n",
      "Epoch 15/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0266 - accuracy: 0.8669 - val_loss: 0.0256 - val_accuracy: 0.8770\n",
      "Epoch 16/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0265 - accuracy: 0.8672 - val_loss: 0.0255 - val_accuracy: 0.8774\n",
      "Epoch 17/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0264 - accuracy: 0.8673 - val_loss: 0.0254 - val_accuracy: 0.8775\n",
      "Epoch 18/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0263 - accuracy: 0.8678 - val_loss: 0.0253 - val_accuracy: 0.8777\n",
      "Epoch 19/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0262 - accuracy: 0.8681 - val_loss: 0.0252 - val_accuracy: 0.8779\n",
      "Epoch 20/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0261 - accuracy: 0.8683 - val_loss: 0.0252 - val_accuracy: 0.8780\n",
      "Epoch 21/200\n",
      "469/469 [==============================] - 5s 10ms/step - loss: 0.0260 - accuracy: 0.8686 - val_loss: 0.0251 - val_accuracy: 0.8783\n",
      "Epoch 22/200\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0259 - accuracy: 0.8688 - val_loss: 0.0250 - val_accuracy: 0.8782\n",
      "Epoch 23/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0259 - accuracy: 0.8690 - val_loss: 0.0249 - val_accuracy: 0.8782\n",
      "Epoch 24/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0258 - accuracy: 0.8693 - val_loss: 0.0248 - val_accuracy: 0.8785\n",
      "Epoch 25/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0257 - accuracy: 0.8697 - val_loss: 0.0247 - val_accuracy: 0.8787\n",
      "Epoch 26/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0256 - accuracy: 0.8699 - val_loss: 0.0246 - val_accuracy: 0.8793\n",
      "Epoch 27/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0255 - accuracy: 0.8702 - val_loss: 0.0246 - val_accuracy: 0.8796\n",
      "Epoch 28/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0254 - accuracy: 0.8705 - val_loss: 0.0245 - val_accuracy: 0.8798\n",
      "Epoch 29/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0254 - accuracy: 0.8706 - val_loss: 0.0244 - val_accuracy: 0.8801\n",
      "Epoch 30/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0253 - accuracy: 0.8709 - val_loss: 0.0243 - val_accuracy: 0.8803\n",
      "Epoch 31/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0252 - accuracy: 0.8709 - val_loss: 0.0242 - val_accuracy: 0.8805\n",
      "Epoch 32/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0251 - accuracy: 0.8712 - val_loss: 0.0242 - val_accuracy: 0.8807\n",
      "Epoch 33/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0251 - accuracy: 0.8713 - val_loss: 0.0241 - val_accuracy: 0.8809\n",
      "Epoch 34/200\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0250 - accuracy: 0.8716 - val_loss: 0.0240 - val_accuracy: 0.8809\n",
      "Epoch 35/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0249 - accuracy: 0.8718 - val_loss: 0.0239 - val_accuracy: 0.8814\n",
      "Epoch 36/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0248 - accuracy: 0.8720 - val_loss: 0.0239 - val_accuracy: 0.8815\n",
      "Epoch 37/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0248 - accuracy: 0.8723 - val_loss: 0.0238 - val_accuracy: 0.8818\n",
      "Epoch 38/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0247 - accuracy: 0.8726 - val_loss: 0.0237 - val_accuracy: 0.8818\n",
      "Epoch 39/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0246 - accuracy: 0.8728 - val_loss: 0.0236 - val_accuracy: 0.8818\n",
      "Epoch 40/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0245 - accuracy: 0.8730 - val_loss: 0.0236 - val_accuracy: 0.8818\n",
      "Epoch 41/200\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0245 - accuracy: 0.8734 - val_loss: 0.0235 - val_accuracy: 0.8821\n",
      "Epoch 42/200\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 0.0244 - accuracy: 0.8735 - val_loss: 0.0234 - val_accuracy: 0.8823\n",
      "Epoch 43/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0243 - accuracy: 0.8737 - val_loss: 0.0234 - val_accuracy: 0.8823\n",
      "Epoch 44/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0243 - accuracy: 0.8739 - val_loss: 0.0233 - val_accuracy: 0.8826\n",
      "Epoch 45/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0242 - accuracy: 0.8740 - val_loss: 0.0232 - val_accuracy: 0.8825\n",
      "Epoch 46/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0241 - accuracy: 0.8742 - val_loss: 0.0232 - val_accuracy: 0.8825\n",
      "Epoch 47/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0241 - accuracy: 0.8744 - val_loss: 0.0231 - val_accuracy: 0.8826\n",
      "Epoch 48/200\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 0.0240 - accuracy: 0.8745 - val_loss: 0.0230 - val_accuracy: 0.8828\n",
      "Epoch 49/200\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0239 - accuracy: 0.8747 - val_loss: 0.0230 - val_accuracy: 0.8828\n",
      "Epoch 50/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0239 - accuracy: 0.8749 - val_loss: 0.0229 - val_accuracy: 0.8836\n",
      "Epoch 51/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0238 - accuracy: 0.8752 - val_loss: 0.0228 - val_accuracy: 0.8838\n",
      "Epoch 52/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0237 - accuracy: 0.8753 - val_loss: 0.0228 - val_accuracy: 0.8838\n",
      "Epoch 53/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0237 - accuracy: 0.8756 - val_loss: 0.0227 - val_accuracy: 0.8841\n",
      "Epoch 54/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0236 - accuracy: 0.8758 - val_loss: 0.0227 - val_accuracy: 0.8842\n",
      "Epoch 55/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0236 - accuracy: 0.8760 - val_loss: 0.0226 - val_accuracy: 0.8843\n",
      "Epoch 56/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0235 - accuracy: 0.8761 - val_loss: 0.0225 - val_accuracy: 0.8844\n",
      "Epoch 57/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0234 - accuracy: 0.8764 - val_loss: 0.0225 - val_accuracy: 0.8843\n",
      "Epoch 58/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0234 - accuracy: 0.8765 - val_loss: 0.0224 - val_accuracy: 0.8842\n",
      "Epoch 59/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0233 - accuracy: 0.8768 - val_loss: 0.0224 - val_accuracy: 0.8843\n",
      "Epoch 60/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0233 - accuracy: 0.8769 - val_loss: 0.0223 - val_accuracy: 0.8846\n",
      "Epoch 61/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0232 - accuracy: 0.8771 - val_loss: 0.0223 - val_accuracy: 0.8848\n",
      "Epoch 62/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0231 - accuracy: 0.8773 - val_loss: 0.0222 - val_accuracy: 0.8849\n",
      "Epoch 63/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0231 - accuracy: 0.8774 - val_loss: 0.0221 - val_accuracy: 0.8849\n",
      "Epoch 64/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0230 - accuracy: 0.8778 - val_loss: 0.0221 - val_accuracy: 0.8852\n",
      "Epoch 65/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0230 - accuracy: 0.8779 - val_loss: 0.0220 - val_accuracy: 0.8851\n",
      "Epoch 66/200\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0229 - accuracy: 0.8780 - val_loss: 0.0220 - val_accuracy: 0.8850\n",
      "Epoch 67/200\n",
      "469/469 [==============================] - 5s 10ms/step - loss: 0.0229 - accuracy: 0.8781 - val_loss: 0.0219 - val_accuracy: 0.8853\n",
      "Epoch 68/200\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0228 - accuracy: 0.8781 - val_loss: 0.0219 - val_accuracy: 0.8856\n",
      "Epoch 69/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0228 - accuracy: 0.8786 - val_loss: 0.0218 - val_accuracy: 0.8856\n",
      "Epoch 70/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0227 - accuracy: 0.8786 - val_loss: 0.0218 - val_accuracy: 0.8857\n",
      "Epoch 71/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0227 - accuracy: 0.8787 - val_loss: 0.0217 - val_accuracy: 0.8857\n",
      "Epoch 72/200\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.0226 - accuracy: 0.8790 - val_loss: 0.0217 - val_accuracy: 0.8859\n",
      "Epoch 73/200\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.0226 - accuracy: 0.8791 - val_loss: 0.0216 - val_accuracy: 0.8860\n",
      "Epoch 74/200\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0225 - accuracy: 0.8794 - val_loss: 0.0216 - val_accuracy: 0.8863\n",
      "Epoch 75/200\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.0225 - accuracy: 0.8795 - val_loss: 0.0215 - val_accuracy: 0.8862\n",
      "Epoch 76/200\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0224 - accuracy: 0.8796 - val_loss: 0.0215 - val_accuracy: 0.8866\n",
      "Epoch 77/200\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.0224 - accuracy: 0.8798 - val_loss: 0.0214 - val_accuracy: 0.8870\n",
      "Epoch 78/200\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0223 - accuracy: 0.8802 - val_loss: 0.0214 - val_accuracy: 0.8871\n",
      "Epoch 79/200\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.0223 - accuracy: 0.8803 - val_loss: 0.0213 - val_accuracy: 0.8871\n",
      "Epoch 80/200\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.0222 - accuracy: 0.8805 - val_loss: 0.0213 - val_accuracy: 0.8871\n",
      "Epoch 81/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0222 - accuracy: 0.8806 - val_loss: 0.0212 - val_accuracy: 0.8875\n",
      "Epoch 82/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0221 - accuracy: 0.8808 - val_loss: 0.0212 - val_accuracy: 0.8876\n",
      "Epoch 83/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0221 - accuracy: 0.8808 - val_loss: 0.0211 - val_accuracy: 0.8880\n",
      "Epoch 84/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0220 - accuracy: 0.8809 - val_loss: 0.0211 - val_accuracy: 0.8884\n",
      "Epoch 85/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0220 - accuracy: 0.8812 - val_loss: 0.0210 - val_accuracy: 0.8886\n",
      "Epoch 86/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0219 - accuracy: 0.8813 - val_loss: 0.0210 - val_accuracy: 0.8886\n",
      "Epoch 87/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0219 - accuracy: 0.8814 - val_loss: 0.0210 - val_accuracy: 0.8889\n",
      "Epoch 88/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0218 - accuracy: 0.8816 - val_loss: 0.0209 - val_accuracy: 0.8891\n",
      "Epoch 89/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0218 - accuracy: 0.8816 - val_loss: 0.0209 - val_accuracy: 0.8894\n",
      "Epoch 90/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0218 - accuracy: 0.8818 - val_loss: 0.0208 - val_accuracy: 0.8896\n",
      "Epoch 91/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0217 - accuracy: 0.8820 - val_loss: 0.0208 - val_accuracy: 0.8897\n",
      "Epoch 92/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0217 - accuracy: 0.8822 - val_loss: 0.0207 - val_accuracy: 0.8898\n",
      "Epoch 93/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0216 - accuracy: 0.8822 - val_loss: 0.0207 - val_accuracy: 0.8902\n",
      "Epoch 94/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0216 - accuracy: 0.8823 - val_loss: 0.0206 - val_accuracy: 0.8904\n",
      "Epoch 95/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0215 - accuracy: 0.8825 - val_loss: 0.0206 - val_accuracy: 0.8905\n",
      "Epoch 96/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0215 - accuracy: 0.8826 - val_loss: 0.0206 - val_accuracy: 0.8905\n",
      "Epoch 97/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0215 - accuracy: 0.8826 - val_loss: 0.0205 - val_accuracy: 0.8907\n",
      "Epoch 98/200\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 0.0214 - accuracy: 0.8829 - val_loss: 0.0205 - val_accuracy: 0.8909\n",
      "Epoch 99/200\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 0.0214 - accuracy: 0.8828 - val_loss: 0.0204 - val_accuracy: 0.8910\n",
      "Epoch 100/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0213 - accuracy: 0.8831 - val_loss: 0.0204 - val_accuracy: 0.8912\n",
      "Epoch 101/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0213 - accuracy: 0.8832 - val_loss: 0.0204 - val_accuracy: 0.8913\n",
      "Epoch 102/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0213 - accuracy: 0.8833 - val_loss: 0.0203 - val_accuracy: 0.8916\n",
      "Epoch 103/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0212 - accuracy: 0.8834 - val_loss: 0.0203 - val_accuracy: 0.8918\n",
      "Epoch 104/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0212 - accuracy: 0.8836 - val_loss: 0.0203 - val_accuracy: 0.8919\n",
      "Epoch 105/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0211 - accuracy: 0.8836 - val_loss: 0.0202 - val_accuracy: 0.8918\n",
      "Epoch 106/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0211 - accuracy: 0.8837 - val_loss: 0.0202 - val_accuracy: 0.8918\n",
      "Epoch 107/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0211 - accuracy: 0.8838 - val_loss: 0.0201 - val_accuracy: 0.8917\n",
      "Epoch 108/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0210 - accuracy: 0.8839 - val_loss: 0.0201 - val_accuracy: 0.8920\n",
      "Epoch 109/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0210 - accuracy: 0.8840 - val_loss: 0.0201 - val_accuracy: 0.8922\n",
      "Epoch 110/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0210 - accuracy: 0.8842 - val_loss: 0.0200 - val_accuracy: 0.8924\n",
      "Epoch 111/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0209 - accuracy: 0.8845 - val_loss: 0.0200 - val_accuracy: 0.8924\n",
      "Epoch 112/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0209 - accuracy: 0.8846 - val_loss: 0.0200 - val_accuracy: 0.8927\n",
      "Epoch 113/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0208 - accuracy: 0.8847 - val_loss: 0.0199 - val_accuracy: 0.8927\n",
      "Epoch 114/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0208 - accuracy: 0.8847 - val_loss: 0.0199 - val_accuracy: 0.8928\n",
      "Epoch 115/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0208 - accuracy: 0.8849 - val_loss: 0.0198 - val_accuracy: 0.8928\n",
      "Epoch 116/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0207 - accuracy: 0.8850 - val_loss: 0.0198 - val_accuracy: 0.8928\n",
      "Epoch 117/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0207 - accuracy: 0.8852 - val_loss: 0.0198 - val_accuracy: 0.8929\n",
      "Epoch 118/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0207 - accuracy: 0.8852 - val_loss: 0.0197 - val_accuracy: 0.8930\n",
      "Epoch 119/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0206 - accuracy: 0.8853 - val_loss: 0.0197 - val_accuracy: 0.8931\n",
      "Epoch 120/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0206 - accuracy: 0.8854 - val_loss: 0.0197 - val_accuracy: 0.8932\n",
      "Epoch 121/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0206 - accuracy: 0.8856 - val_loss: 0.0196 - val_accuracy: 0.8932\n",
      "Epoch 122/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0205 - accuracy: 0.8856 - val_loss: 0.0196 - val_accuracy: 0.8933\n",
      "Epoch 123/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0205 - accuracy: 0.8858 - val_loss: 0.0196 - val_accuracy: 0.8933\n",
      "Epoch 124/200\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0205 - accuracy: 0.8859 - val_loss: 0.0195 - val_accuracy: 0.8933\n",
      "Epoch 125/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0204 - accuracy: 0.8860 - val_loss: 0.0195 - val_accuracy: 0.8937\n",
      "Epoch 126/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0204 - accuracy: 0.8862 - val_loss: 0.0195 - val_accuracy: 0.8937\n",
      "Epoch 127/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0204 - accuracy: 0.8861 - val_loss: 0.0194 - val_accuracy: 0.8937\n",
      "Epoch 128/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0203 - accuracy: 0.8860 - val_loss: 0.0194 - val_accuracy: 0.8938\n",
      "Epoch 129/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0203 - accuracy: 0.8862 - val_loss: 0.0194 - val_accuracy: 0.8936\n",
      "Epoch 130/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0203 - accuracy: 0.8863 - val_loss: 0.0194 - val_accuracy: 0.8938\n",
      "Epoch 131/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0202 - accuracy: 0.8864 - val_loss: 0.0193 - val_accuracy: 0.8939\n",
      "Epoch 132/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0202 - accuracy: 0.8866 - val_loss: 0.0193 - val_accuracy: 0.8941\n",
      "Epoch 133/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0202 - accuracy: 0.8866 - val_loss: 0.0193 - val_accuracy: 0.8945\n",
      "Epoch 134/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0201 - accuracy: 0.8867 - val_loss: 0.0192 - val_accuracy: 0.8945\n",
      "Epoch 135/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0201 - accuracy: 0.8868 - val_loss: 0.0192 - val_accuracy: 0.8945\n",
      "Epoch 136/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0201 - accuracy: 0.8868 - val_loss: 0.0192 - val_accuracy: 0.8946\n",
      "Epoch 137/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0200 - accuracy: 0.8870 - val_loss: 0.0191 - val_accuracy: 0.8949\n",
      "Epoch 138/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0200 - accuracy: 0.8871 - val_loss: 0.0191 - val_accuracy: 0.8951\n",
      "Epoch 139/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0200 - accuracy: 0.8873 - val_loss: 0.0191 - val_accuracy: 0.8951\n",
      "Epoch 140/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0200 - accuracy: 0.8873 - val_loss: 0.0191 - val_accuracy: 0.8952\n",
      "Epoch 141/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0199 - accuracy: 0.8875 - val_loss: 0.0190 - val_accuracy: 0.8952\n",
      "Epoch 142/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0199 - accuracy: 0.8875 - val_loss: 0.0190 - val_accuracy: 0.8954\n",
      "Epoch 143/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0199 - accuracy: 0.8878 - val_loss: 0.0190 - val_accuracy: 0.8954\n",
      "Epoch 144/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0198 - accuracy: 0.8878 - val_loss: 0.0189 - val_accuracy: 0.8955\n",
      "Epoch 145/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0198 - accuracy: 0.8879 - val_loss: 0.0189 - val_accuracy: 0.8955\n",
      "Epoch 146/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0198 - accuracy: 0.8880 - val_loss: 0.0189 - val_accuracy: 0.8955\n",
      "Epoch 147/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0198 - accuracy: 0.8880 - val_loss: 0.0189 - val_accuracy: 0.8956\n",
      "Epoch 148/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0197 - accuracy: 0.8881 - val_loss: 0.0188 - val_accuracy: 0.8956\n",
      "Epoch 149/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0197 - accuracy: 0.8883 - val_loss: 0.0188 - val_accuracy: 0.8956\n",
      "Epoch 150/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0197 - accuracy: 0.8883 - val_loss: 0.0188 - val_accuracy: 0.8956\n",
      "Epoch 151/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0196 - accuracy: 0.8885 - val_loss: 0.0187 - val_accuracy: 0.8957\n",
      "Epoch 152/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0196 - accuracy: 0.8886 - val_loss: 0.0187 - val_accuracy: 0.8959\n",
      "Epoch 153/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0196 - accuracy: 0.8887 - val_loss: 0.0187 - val_accuracy: 0.8960\n",
      "Epoch 154/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0196 - accuracy: 0.8888 - val_loss: 0.0187 - val_accuracy: 0.8959\n",
      "Epoch 155/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0195 - accuracy: 0.8888 - val_loss: 0.0186 - val_accuracy: 0.8959\n",
      "Epoch 156/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0195 - accuracy: 0.8889 - val_loss: 0.0186 - val_accuracy: 0.8959\n",
      "Epoch 157/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0195 - accuracy: 0.8889 - val_loss: 0.0186 - val_accuracy: 0.8961\n",
      "Epoch 158/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0195 - accuracy: 0.8892 - val_loss: 0.0186 - val_accuracy: 0.8962\n",
      "Epoch 159/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0194 - accuracy: 0.8893 - val_loss: 0.0185 - val_accuracy: 0.8962\n",
      "Epoch 160/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0194 - accuracy: 0.8893 - val_loss: 0.0185 - val_accuracy: 0.8963\n",
      "Epoch 161/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0194 - accuracy: 0.8894 - val_loss: 0.0185 - val_accuracy: 0.8966\n",
      "Epoch 162/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0194 - accuracy: 0.8895 - val_loss: 0.0185 - val_accuracy: 0.8967\n",
      "Epoch 163/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0193 - accuracy: 0.8896 - val_loss: 0.0184 - val_accuracy: 0.8968\n",
      "Epoch 164/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0193 - accuracy: 0.8897 - val_loss: 0.0184 - val_accuracy: 0.8968\n",
      "Epoch 165/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0193 - accuracy: 0.8898 - val_loss: 0.0184 - val_accuracy: 0.8970\n",
      "Epoch 166/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0192 - accuracy: 0.8898 - val_loss: 0.0184 - val_accuracy: 0.8970\n",
      "Epoch 167/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0192 - accuracy: 0.8899 - val_loss: 0.0183 - val_accuracy: 0.8970\n",
      "Epoch 168/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0192 - accuracy: 0.8900 - val_loss: 0.0183 - val_accuracy: 0.8970\n",
      "Epoch 169/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0192 - accuracy: 0.8901 - val_loss: 0.0183 - val_accuracy: 0.8970\n",
      "Epoch 170/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0191 - accuracy: 0.8903 - val_loss: 0.0183 - val_accuracy: 0.8970\n",
      "Epoch 171/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0191 - accuracy: 0.8902 - val_loss: 0.0182 - val_accuracy: 0.8970\n",
      "Epoch 172/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0191 - accuracy: 0.8903 - val_loss: 0.0182 - val_accuracy: 0.8971\n",
      "Epoch 173/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0191 - accuracy: 0.8904 - val_loss: 0.0182 - val_accuracy: 0.8971\n",
      "Epoch 174/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0191 - accuracy: 0.8906 - val_loss: 0.0182 - val_accuracy: 0.8972\n",
      "Epoch 175/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0190 - accuracy: 0.8906 - val_loss: 0.0181 - val_accuracy: 0.8972\n",
      "Epoch 176/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0190 - accuracy: 0.8908 - val_loss: 0.0181 - val_accuracy: 0.8973\n",
      "Epoch 177/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0190 - accuracy: 0.8909 - val_loss: 0.0181 - val_accuracy: 0.8972\n",
      "Epoch 178/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0190 - accuracy: 0.8909 - val_loss: 0.0181 - val_accuracy: 0.8972\n",
      "Epoch 179/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0189 - accuracy: 0.8910 - val_loss: 0.0181 - val_accuracy: 0.8974\n",
      "Epoch 180/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0189 - accuracy: 0.8911 - val_loss: 0.0180 - val_accuracy: 0.8976\n",
      "Epoch 181/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0189 - accuracy: 0.8913 - val_loss: 0.0180 - val_accuracy: 0.8976\n",
      "Epoch 182/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0189 - accuracy: 0.8914 - val_loss: 0.0180 - val_accuracy: 0.8976\n",
      "Epoch 183/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0188 - accuracy: 0.8915 - val_loss: 0.0180 - val_accuracy: 0.8976\n",
      "Epoch 184/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0188 - accuracy: 0.8917 - val_loss: 0.0179 - val_accuracy: 0.8977\n",
      "Epoch 185/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0188 - accuracy: 0.8918 - val_loss: 0.0179 - val_accuracy: 0.8977\n",
      "Epoch 186/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0188 - accuracy: 0.8918 - val_loss: 0.0179 - val_accuracy: 0.8979\n",
      "Epoch 187/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0188 - accuracy: 0.8920 - val_loss: 0.0179 - val_accuracy: 0.8979\n",
      "Epoch 188/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0187 - accuracy: 0.8921 - val_loss: 0.0179 - val_accuracy: 0.8979\n",
      "Epoch 189/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0187 - accuracy: 0.8922 - val_loss: 0.0178 - val_accuracy: 0.8979\n",
      "Epoch 190/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0187 - accuracy: 0.8923 - val_loss: 0.0178 - val_accuracy: 0.8978\n",
      "Epoch 191/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0187 - accuracy: 0.8924 - val_loss: 0.0178 - val_accuracy: 0.8979\n",
      "Epoch 192/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0186 - accuracy: 0.8925 - val_loss: 0.0178 - val_accuracy: 0.8980\n",
      "Epoch 193/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0186 - accuracy: 0.8926 - val_loss: 0.0178 - val_accuracy: 0.8982\n",
      "Epoch 194/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0186 - accuracy: 0.8928 - val_loss: 0.0177 - val_accuracy: 0.8983\n",
      "Epoch 195/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0186 - accuracy: 0.8928 - val_loss: 0.0177 - val_accuracy: 0.8985\n",
      "Epoch 196/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0186 - accuracy: 0.8929 - val_loss: 0.0177 - val_accuracy: 0.8985\n",
      "Epoch 197/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0185 - accuracy: 0.8928 - val_loss: 0.0177 - val_accuracy: 0.8984\n",
      "Epoch 198/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0185 - accuracy: 0.8930 - val_loss: 0.0176 - val_accuracy: 0.8986\n",
      "Epoch 199/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0185 - accuracy: 0.8929 - val_loss: 0.0176 - val_accuracy: 0.8987\n",
      "Epoch 200/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0185 - accuracy: 0.8929 - val_loss: 0.0176 - val_accuracy: 0.8987\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/device:GPU:0'):\n",
    "    model.fit(X_train, y_train,\n",
    "          batch_size=128,\n",
    "          epochs=200,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "63853959-d1fc-4e1e-a02a-dc8105561074",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "d3253041-e647-423c-92eb-6001908937a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_valid, y_valid) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "bd636410-16a3-48b0-96bf-e0acc97c0c29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "6d835c23-4c1c-4b18-9bdc-94c4929b12e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "603c768c-4eb1-4c30-ac9d-884724c13831",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeoAAAGuCAYAAABfpEVAAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/H5lhTAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAj1UlEQVR4nO3de5yN5frH8UfjOAYhEjkfNiqkQmFvIUQqbJTIoVRTCSG7XZucdlOSQ04RIeWQnb1fU1460HbKKadNJDnFVMwQNc7G/P57PNflN2vWmllrzTVrfd5/3d/XPWutO3O4eta17vvJk56enu4AAACTrsvpBQAAgIxRqAEAMIxCDQCAYRRqAAAMo1ADAGAYhRoAAMMo1AAAGEahBgDAMAo1AACGUagBADCMQg0AgGEUagAADKNQAwBgGIUaAADDKNQAABhGoQYAwDAKNQAAhlGoAQAwjEINAIBhFGoAAAyjUAMAYBiFGgAAwyjUAAAYljenFwCE05EjR0SeOHGiyOPHjxd54MCBIvfv398dly9fPsirA4BrcUUNAIBhFGoAAAyjUAMAYFie9PT09JxeRChduXJF5AsXLvj92Llz54p85swZkXfv3i3yhAkT3PHf//53MTd58mSRCxUqJPK4ceNEjo+P93udyFhSUpLIdevWFfnUqVMBPV/x4sXdcXJycpbXhdxjz549Irds2VLk7du3i1yqVKlQLwlZMHPmTJGfeeYZd6zrxN69e0WuUaNG6BbmB66oAQAwjEINAIBhFGoAAAzLFfuoT58+7Y7T0tLE3I4dO0T+4osvRNY9yBkzZgRtXZUqVRJ50KBB7njWrFlirlixYiI3bdpU5ObNmwdtXdHu8OHD7rhZs2Zi7rfffhM5T548IuvvU4ECBUQ+fvy4Oz5w4ICYq1ixosgxMTH+LTgX2bdvn8j637NBgwbhXE5YbNy4UeQWLVrk0EoQiBUrVoj84osvinzddRlfp+q/CzmNK2oAAAyjUAMAYBiFGgAAw0z2qI8ePSpyvXr13LHuiYWT7mnoPrR3b/QTTzwh5kqXLi1yXFycyOy99N+lS5dE9vakHcdx2rRp44712d6Z8f6sOY7jjBkzRuQmTZq44+rVq4s5/fkH/TMQCXTf7/vvvxc5UnrU3uMldF/+hx9+CPdykAX6+3T+/PkcWkn2cUUNAIBhFGoAAAyjUAMAYJjJHnXJkiVFvvHGG91xMHvUrVq18vm6n3zyich6T63eo4vwGDJkiMj6HPXsWLVqlcj6fPcOHTq4Y/3zsW3btqCtw6pJkyaJrH+HIkVqaqo7fv3118Wc957kjsPnS6zQ91547bXXfH59/fr13bE+f6Nw4cJBW1cwcEUNAIBhFGoAAAwz+da3vgXknDlz3PGSJUvE3N133y1yp06dfD63d3vNf/7zHzGXP39+kX/99VeRJ06c6PO5ERp6i9X8+fNF9nWnVu9b1Y5z7c9H9+7dRS5fvrzItWrVEnno0KHuWP8sRvgdYx3HufYI30jlvQWipn8mkDN+/PFHkdu2bSvyyZMnfT4+ISHBHeujg63hihoAAMMo1AAAGEahBgDAMJM9au2uu+5yx3Xq1BFzuq/80ksvifzmm2+KPGrUqAwfq5UpU0ZkvU0DoZGUlCTy7bffLrK+dam+Jd1jjz3mjmfOnCnm9BYOPf/II4+IHBsbK3LZsmXdsT5S9oMPPhD5b3/7m8i6/50b/PzzzyLr702k8tXfvO+++8K4EmTkvffeEzmz44I7duwo8r333hv0NYUKV9QAABhGoQYAwDAKNQAAhuWKHrWXPsZTK168uM957xGITZs2FXO614nwSUlJccdvvPGGmNPHxnqPlHUcx6lcubLI8fHx7lh/DkHfxlLn7Dh79qzIY8eOFVkfv5kb6KMV9X9jpNBHxe7cuTPDr9VHDSM8Mvv90p8Z0d8n7+eTchuuqAEAMIxCDQCAYRRqAAAMy3U96swMGDBA5E2bNom8dOlSd/zdd9+JuVtvvTVk64J0+fJlkQcPHuyO9Vne+hzezz//XORq1aqJfOnSpWAsMdsOHjyY00vItl27dvmcD2aPPye98sorInv3j2d2dgNCx3tmwkMPPRTQY/VtLmvWrBmEFeUMrqgBADCMQg0AgGEUagAADIu4HrXuH82YMUPkFStWuGPd83j44YdFbty4scj63sbsu866n376SWTdl/basGGDyDVq1PD53Pp+5gidhg0b5vQS/l8XLlwQecuWLSLrvwuLFi3K8Ln0/veCBQtmc3Xw15o1a9zxN9984/NrO3fuLHKvXr1CsaQcwRU1AACGUagBADAs4t761kqUKCGyd2tPmzZtxNyECRN85tmzZ4vcqVMnkePi4rK4yujz3HPPiZyenu6OdYshs7e6c8qVK1dE1kcYev+bIpW+5Wgg9C009b/nqlWrRNbb3S5evOiO33nnHTGXlpYmcuHChUVu1aqVyPrtbO8Wv1q1al2zdoTG5s2bRe7Zs2eGX9u+fXuR9S1rI6lFwRU1AACGUagBADCMQg0AgGER36PWGjRo4I71EaIDBw4U+eOPPxa5T58+Iu/fv1/kIUOGuOMiRYpka52RZtu2bSKvXr1aZO9WN73Nwirdk9bb9e68885wLickYmNjRdb/jQ8++KDIf/rTn/x+7vXr14use/p588o/T/ozIN6tYd4jaB3n2lvY6qNOdc+6fPnyIntve1mqVCm9dASJ/oxDo0aN/H6sPjpYf08jCVfUAAAYRqEGAMAwCjUAAIblSY+GzZ5+On/+vMj66MqWLVuKrP/p/vrXv7pjX0cSRiPdj9Q9xLJly7rj3bt3i7mc3J+ub8fpPU7S+5kEx7m2tz5v3jyRI+H2iHPnzhX5v//9b9Ceu1u3biLrHmTlypWD9lrLli0T+YEHHhDZe0tE/fOI4PnHP/4hckJCgt+P1fvwI/mzBFxRAwBgGIUaAADDKNQAABgWdfuofdFnwzZr1kzkmJgYkXX/8t///rc73rt3r5gLZH9pNPL+21vqSU+bNk3kl156yR1XqlRJzL3yyisiR0JPWtNnL/s6i9myTz/91Oe8PjMBwZGUlCTykiVL/H5s7969RY7knrTGFTUAAIZRqAEAMIxCDQCAYVHdo9b78D755BOR9d5f3b/U7rrrLnds9R7KVvXo0SNHXlf3zN544w2Rp06dKrK3T6bvf4vI0bFjx5xeQkTS59+npKT4/PrWrVu748mTJ4dkTbkBV9QAABhGoQYAwDAKNQAAhkV8jzo5OVnkKVOmuOP3339fzB09ejSg59b7qr37avV9e6OdPhdd5zlz5rhjff5vMC1YsEDkfv36ifzbb7+J/MILL4g8fvz40CwMiALHjx8XWd/TXRs6dKg7jsRzCfzFFTUAAIZRqAEAMCzXv/WdmpoqcmJiosgjR44U+YcffsjyazVv3lxkfUu2O+64I8vPHel0K0Bnb9tBf8+eeOIJkYsUKSLyd999J/K7777rjtesWSPmDh06JHLVqlVFfuSRR0TWb30jMulWzOHDh91xlSpVwr2ciDF48GCRr1y5EtDj69SpE8zl5FpcUQMAYBiFGgAAwyjUAAAYlit61GfOnHHHR44cEXPdu3cXedu2bVl+nVatWok8YsQIkb1HhDoOW7CCKS0tzR3rHvWsWbNELlGihMg7d+70+3Xuv/9+kdu0aSPy888/7/dzIXLo3+VAe6m4ynssr76Npd6OVaBAAZGHDx8ucuHChYO8utyJK2oAAAyjUAMAYBiFGgAAw0z0qM+dOyfygAEDRF67dq07/v7777P1Wm3btnXHw4YNE3P16tUTOV++fNl6LVx1yy23iNyyZUuRv/rqqwwfq4921bem1EqXLu2O4+PjxVwojydF5Fi5cqU7btGiRQ6uJPfxnm2R2e+q99hlx5FHhuIqrqgBADCMQg0AgGEUagAADAtLj1qfr/zPf/5TZN2f9J6zG6jY2FiRR40aJfKzzz7rjqP5tmnhVrRoUZH1/sp58+a540DP1x49erTIffv2dcclS5YM6LkQnfRZ34AlXFEDAGAYhRoAAMMo1AAAGBaWHvW//vUvkfXZzZmpX7++O3700UfFXN688j/hqaeeErlgwYIBvRbCIy4uTmTvZwe8YyAUOnXqJPL06dNzaCWRp1y5cu64Xbt2Yi4xMTHcy4kIXFEDAGAYhRoAAMMo1AAAGJYnnQ2EAACYxRU1AACGUagBADCMQg0AgGEUagAADKNQAwBgGIUaAADDKNQAABhGoQYAwDAKNQAAhlGoAQAwjEINAIBhFGoAAAyjUAMAYBiFGgAAwyjUAAAYRqEGAMAwCjUAAIZRqAEAMIxCDQCAYRRqAAAMo1ADAGAYhRoAAMMo1AAAGEahBgDAMAo1AACGUagBADCMQg0AgGEUagAADKNQAwBgGIUaAADDKNQAABhGoQYAwDAKNQAAhlGoAQAwjEINAIBhFGoAAAyjUAMAYBiFGgAAwyjUAAAYRqEGAMAwCjUAAIZRqAEAMIxCDQCAYRRqAAAMo1ADAGAYhRoAAMMo1AAAGEahBgDAMAo1AACGUagBADCMQg0AgGEUagAADKNQAwBgGIUaAADDKNQAABhGoQYAwDAKNQAAhlGoAQAwjEINAIBhFGoAAAyjUAMAYBiFGgAAwyjUAAAYRqEGAMAwCjUAAIZRqAEAMIxCDQCAYRRqAAAMo1ADAGAYhRoAAMPy5vQCAMAfo0aNEnnYsGHuuEGDBmLuiy++ELlYsWKhWxgQYlxRAwBgGIUaAADDKNQAABiWJz09PT2nFwGEy4ULF0S+dOmSyGvXrhU5KSlJ5J49e7rjvHn5iEconTp1SuTq1auLfPLkSXecJ08eMbdt2zaRb7vttuAuDkGRkpIi8uXLl0XetGmTO37ooYfE3HXXBe86s3fv3iK/++67IsfExATttbKCK2oAAAyjUAMAYBiFGgAAw2iyIeJ4e5vjxo0TcytXrhR548aNAT23t2ft3ceL4IuNjRX5wQcfFHnOnDlhXA2y4tdffxV53rx5Is+YMUPkK1euiPzTTz+5Y92T1p9LyA79s1S8eHGRR48eLXKBAgWC9tr+4IoaAADDKNQAABhGoQYAwLCI30d96NAhkb29iOXLl4u5zZs3+3yuDz/8UOTy5cuL/OWXX7rjXr16iblKlSr5Xij8lpycLPLEiRMzzOfOnRNz+se9cuXKIpcsWVLkLVu2iHzjjTe64+3bt4u5UqVK+Vg1skv3CYcPH+6O2Udtk/47OH/+/Cw/l/7dDWaPOjN79+4VuWrVqmF7bcfhihoAANMo1AAAGEahBgDAsIjbR71u3TqRu3TpIvKxY8fcse55dOzYUeQjR46I3L17d5+v7X0+3UedMmWKz8fiqvPnz4use5PTpk0T+fTp034/t+5Vrlq1SmR91rC3J+048udHvy496uDSPwe67wz72rdvL3JmPeqyZcuKPHjwYHes91hndtb3mjVrRF66dKnPr7eMK2oAAAyjUAMAYFiue+tbv/2ht1+1a9dO5NTUVJEffvhhd6zfUtW30UtLSxO5T58+Ii9cuDDDdd5zzz0ZzsE33b5ISEjI8nPVrl1b5NWrV4tctGhRkU+cOJHl10Jw6VuQ7t692+/HbtiwQeQKFSqIXKxYsawvDH7r0KGDyN5bk/5/9NvZcXFxWX7tp59+WuRatWqJ7D2eVNN/6ytWrJjldQQDV9QAABhGoQYAwDAKNQAAhuW6HvXXX38tcuvWrX1+fdeuXUWePXu2O87sVmVr164V2VdP2nHkMaG6NwP/BXr7who1aojcvHlzdzxmzBgxp3vS2uHDhwN6bYROkSJFRB44cKDI8fHxGT5Wz+mjYfVWTISG7jln9vsXTFu3bhU5JSXF78fqzzTkzZuzpZIragAADKNQAwBgGIUaAADDckWPetKkSe5Y96n0rc6GDRsm8tChQ0XOrC/tNWDAAL+/1nEcZ9GiRe44NjY2oMfiqqlTp4p89913i9ymTRuR9TGfhQsXzvJrHz9+PMuPRWg99dRTIvvqUSP66M8U6dvfnj171u/nGjJkSFDWFCxcUQMAYBiFGgAAwyjUAAAYZrJHPX36dJG9fWndY37kkUdEfvnll0XOly9fhq+jb2m4Y8cOkfft2yeyvi2mt3fuOI5z5513Zvha8J/eP/vss8+G7bVXrlwZttdC9njP/c/slofI/fQ5/YMGDRL5u+++E/nixYt+P3fTpk1FtvbzZGs1AABAoFADAGAYhRoAAMNM9KjPnz8v8qhRo0T27pXWPWnv2d3+8N4PVZ8Drs8R1/T9Tfv27RvQayM8lixZ4o5///13Mac/Z6D34W/ZssXnc3vvd16lSpWsLhFB4O0j6u8jbDh16pTIixcvFnnZsmV+P1diYqLIgX7Pr7/+epHnzZvnjps0aSLmfH22KSdwRQ0AgGEUagAADDPx1ndaWprIx44dy/Brx48fL/KZM2dE9r7t6TjyWE/HcZz169e7Y/22qH4rRecnn3xS5Pz582e4TgTPpUuXRP75559F1sfGzp8/P8Pn8m7pcZzMt2GUL19e5Pfff9/vxwLR6JdffnHHzZo1E3P79+8P82quat++vcht27bNoZUEjr80AAAYRqEGAMAwCjUAAIaZ6FHHxMSIXKZMGZF//fVXd1yiRAkxF+hH9CtUqOCO9cf1jxw5IrK+fWL9+vUDei34z/s5haNHj4o53efS3yd9S1FvX/n+++8XcwsWLBA5NTXV57r0MbOfffaZO+7WrZuY0z/HQLTT2yF1DkSgny/RvNuxHMdx+vfv747r1auX5XWFA1fUAAAYRqEGAMAwCjUAAIaZ6FEXLFhQ5LVr14rcqFEjd5ycnCzmateuLXKPHj1Efvzxx0UuXLhwhl+re5/x8fG+lo1s0Hvnt2/f7o4bNmzo87FTp04VuUWLFiJXrVrVHZ87d07M/e9//xN548aNPl/L+/kIx3Gc3r17u2N9hKhed968Jn69IlYgt7n88ssvRe7YsWNI1gTHuemmm9zx5s2bxdzHH38scqtWrUTOztkUs2bNEnn48OFZfi5ruKIGAMAwCjUAAIZRqAEAMCxPenY2tuVC+/btc8c1atQQc7rPpW/J1qlTp9AtLMLpnvTEiRNFfumllzJ8rN6vPGPGDJH1ZxzOnj3rjh944AExt2rVKpELFCgg8tixY0X29s4dR571rXXp0kVkfQZ5XFxcho91HMe5+eabfc5D8u5bD/Q8haSkJJH1mQnIffTtkjP7ffv222/dMfuoAQBAllGoAQAwjEINAIBhUbfR09vH0D1p3efS50TDf/pc3gkTJog8dOhQkYsUKeKO58yZI+Zat24tsu5JHz58WOS+ffu649WrV4u52267TeSFCxeKXLNmTZEvXLggcr9+/dzx7NmzxdzcuXNF1p9x0PQ+7B9++MHn10N69dVX3fGYMWMCeuzMmTMzfC7kTlu3bs3pJYQMV9QAABhGoQYAwDAKNQAAhkVdj1r3KBEan376qci6J633OCYmJrrjO+64Q8zt3btX5OnTp4s8f/58kb3ne0+ePFnM6T3ZRYsWvWbtXnqfdZ06ddyx7rvrffa6D6qNHz/e5zx8834vED76TISdO3eKfMstt7jjfPnyhWwd+vz2zp07h+y1chpX1AAAGEahBgDAsKg7QtT7No0+Nk5vz/r9999Fjo2NDdm6Io0+DlPfLlJvsfK+3X369Gkxt2vXroBee9q0ae74iSeeEHOZ3Q4RuZNuae3evdvn1+vtgydOnBC5RIkSwVlYBPAeu+w4jvPaa6+JvGjRIpFPnjzpjjNrLWXG28batGmTmNO3KtV/NzT999v7fHpbpjX81QIAwDAKNQAAhlGoAQAwLOq2Zx04cCCnlxAVKlWqJLLuUetb0q1bty7D5+revbvI9913n8j6qNfrr7/eHdOTjg4NGjQQec+ePT6/np8L//Xq1UvkjRs3+vx677bD7Paovds29S1qM7u1qe5hDxo0SGTrfWkvfloBADCMQg0AgGEUagAADIu6fdS//PKLOy5btqyY032rP/74Q2T2UftP3x5y/fr1Iuue9E033eSOu3btKub0nuuYmJhgLBERZMeOHSLrY2g1/WcvOTlZZPZRX9W4cWORM+tRh4r+npUrV07kHj16iDxixAiR8+bNvR/J4ooaAADDKNQAABhGoQYAwLCo61F76fOB9d5LfcZt5cqVQ74mAIHT5zy3atVK5C1btohMj9p/R48eFXnSpEkiv/3220F7rdq1a4vs3Yetv6d9+/YV2fs5l0jDFTUAAIZRqAEAMIxCDQCAYVHdo16xYoXIrVu3FrlDhw4iT548WeQbb7wxNAsDAKMuX74s8vLly0V+8skn3XFKSoqY69Onj8gPPvigyM2aNRM5Li4uq8uMKFxRAwBgGIUaAADDKNQAABgW1T1qfR517969RV68eLHIet/exIkTRc6fP38QVwcAAFfUAACYRqEGAMCwqH7rW9NvhSckJIg8atQokZOSkkRmuxYAINi4ogYAwDAKNQAAhlGoAQAwjB41AACGcUUNAIBhFGoAAAyjUAMAYBiFGgAAwyjUAAAYRqEGAMAwCjUAAIZRqAEAMIxCDQCAYRRqAAAMo1ADAGAYhRoAAMMo1AAAGEahBgDAMAo1AACGUagBADCMQg0AgGEUagAADKNQAwBgGIUaAADDKNQAABhGoQYAwDAKNQAAhlGoAQAwjEINAIBhFGoAAAyjUAMAYBiFGgAAwyjUAAAYRqEGAMAwCjUAAIZRqAEAMIxCDQCAYRRqAAAMo1ADAGAYhRoAAMMo1AAAGEahBgDAMAo1AACGUagBADCMQg0AgGEUagAADKNQAwBgGIUaAADDKNQAABhGoQYAwDAKNQAAhlGoAQAwjEINAIBhFGoAAAyjUAMAYBiFGgAAwyjUAAAYRqEGAMAwCjUAAIZRqAEAMIxCDQCAYRRqAAAMo1ADAGAYhRoAAMMo1AAAGEahBgDAMAo1AACG5c3pBQCRqnPnziKnp6eLvGTJknAuJ9c5duyYyJ9//rnICQkJ7rh58+ZirkGDBj6f+7HHHhM5JiYmK0sEwoIragAADKNQAwBgGIUaAADDIr5HnZaWJvL+/fvd8YABA8TcsmXLwrEkRKgxY8aI/Nlnn4k8cODAcC4n1/n0009F7tatm8h//PFHho/ds2ePyFOmTPH5WrqHXbNmTX+WCOQIrqgBADCMQg0AgGEUagAADIv4HvWFCxdE9vaibr75ZjGXmpoqclxcXOgWhlxv3LhxIusedf78+UVu165dyNeUm7Vo0UJk/fvnq0cdqMaNG4u8atUqkW+99dagvRaQXVxRAwBgGIUaAADDKNQAABgW8T1qX44ePSry6dOnRaZHDV/Wrl0r8sWLF0Vu3769yPfcc0/I15SbFSpUSOR3331X5EcffVTkM2fOuOMqVaqIuQMHDvh8rZMnT4qcmJgoMj3q6KL/9uvf5cWLF4s8evRon8/nPUv+rbfeyubquKIGAMA0CjUAAIZRqAEAMCyqe9T6/sDInfbt2yfysGHD3PHs2bPFnO6DBmrNmjXu+JtvvhFztWvXFnn8+PHZeq1op3v8devWFdn773/DDTeIucx61NozzzwT4OqQ2+zevVvkhQsXumN9Nvxvv/0mcp48eQJ6rRUrVgS4Ot+4ogYAwDAKNQAAhuVJj/D3f8+ePSuyry1XP/74o8h6ywdsqlevnsg7d+50x3v37hVz1apVy9Zr3XXXXe7422+/FXMbN24UWd9KEdmzYcMGkQcPHuyO161bl63nPnbsmMilS5fO1vMh/IYOHSry1q1bRQ7k7ehixYqJ3K9fP5GbNm0q8r333ity3rzB7SpzRQ0AgGEUagAADKNQAwBgWFRvz9K2b98uMj3q3KFo0aIie7dS6KMAA5WUlCSydyvYddfJ/8/Vt1RFcDVq1Ejk5cuXu+OWLVuKOf15gcy8+uqrIs+YMSPA1SHUzp07J/LIkSNFHjt2rMilSpUSuVmzZiK//vrr7lj/rde3qNU963DjihoAAMMo1AAAGEahBgDAsIjvUes+YvHixd2xPiZuz549YVkTsuedd94Ref369SLffvvt7rhSpUoBPbfuaXv7WI7jOKmpqe64devWYo7bWIbW6tWrRfb2oTdt2pSt527RokW2Ho/QGzdunMhvvvmmyCNGjBBZ76vWfefchCtqAAAMo1ADAGAYhRoAAMMivkddsGBBkb23zps3b164l4Ms+P3330VOSEgQOV++fCJ/+OGH7jg2Njag19J9runTp4tcoUIFd7xs2bKAnhu+JScni9yqVSuRd+3aJfLly5eD9tr6tRAely5dElnvX580aZI7/uijj8RcmzZtRNZn/gf7vO2cxBU1AACGUagBADCMQg0AgGGR8yY+IsYvv/wisj7HWd87WPeVa9So4fdrefvZjuM4b731ls+v9/bMEFwHDx4U+fvvvxc5mD1pTX9fhw8fHrLXwlWTJ08W2XuPccdxnPj4eHdct25dMRdJPejMcEUNAIBhFGoAAAyLnvcO/JCSkpLTS4gaV65cEfnrr792x3qrjP5afSzsqlWrRC5Tpow77tmzp5g7f/68yHPmzBE5PT1d5IEDB4r8wAMPOAiNBg0aiPzBBx+I/Pjjj4usb3uYHfp2pgiPF198UWTvLWodx3F69+7tjqPprW6NK2oAAAyjUAMAYBiFGgAAw/Kk66ZchOvVq5c71keIXn/99SKfPHkyDCuKTrqv7Os2g/pH9JZbbhF59+7dGT62efPmIu/bt0/kI0eOiOztbzuO4xw9ejTD50Z47dixQ2R9tKxXWlqayB06dBD51KlTIvft21dkfZQlQuO+++4TeeXKlSJXrFjRHScmJoo5/XcgknFFDQCAYRRqAAAMo1ADAGBY1PWoFy5c6I67desm5uhRh866detEbtasmcjeW1WWKFFCzH311VciFylSROQBAwaIvHTp0gzXoX/c9b5NnW+++WaRt2zZkuE6YYf+Pk+dOlXk559/XuRatWqJvH79endcrFixIK8ush06dMgdly9fXszFxMSIrPfCv//++yL369fPHRctWlTM7d27V+TSpUsHvNbcgitqAAAMo1ADAGAYhRoAAMOi7vDUypUrZzh38eJFkU+fPi0yvaqsGz9+vMjVqlUT2XubQb23MjP6Vnnevtfy5csDei7d23z44YdFpi+dO+h91LonrRUoUEBk/VkFXJWamipyu3btRPb2jhctWiTm/vKXv4hcqFAhkb3nXDiO7FHrffN6HfSoAQBAjqBQAwBgGIUaAADDoq5Hrffxeen+5KVLl0K9nKjRtWtXkVu3bi2y3iMZCN278u6B1dasWSNy1apVfT633luP3OHtt98O6OsHDx4scnZ+HiNdzZo1RdbnpnvvoaB70pl57733Mpzr0qWLyOXKlQvouXMzrqgBADCMQg0AgGEUagAADIu6s7696tevL/L27dtFfvXVV0UeOXJkqJcEP5w/f17khIQEkUeNGuWOa9euLeZ27twZuoXhmrOb4+PjRe7Tp487/vOf/xy019V7avUZ07qPqulz/YsXLx6UdUWi2bNni/zCCy+IfPbsWb+f69ZbbxV5165dInvPW1ixYoWY09/jSMYVNQAAhlGoAQAwLOq2Z3l17NhR5IMHD4o8bNiwcC4Hfvroo49EHj16tMg33XSTO9a310RoDR06VOS5c+eK7G0vLV68WMzdcMMNIuvjWo8cOSKy93aKL7/8spjL7K1u3S7Rt05FxrztC8e59vjVjRs3uuMlS5b4fK7k5GSRu3fvLvK4cePcccmSJQNaZyThihoAAMMo1AAAGEahBgDAsKjenqV7m/rYwRMnTojMre9yhr7daKNGjUT+8ccfRZ4wYYI7fu6550K2LlzrwIEDIut/f1+3Ha1evbrIDRs2FDkxMVFk/XPhpX9X69WrJ/KGDRtEzp8/f4bPBeQ0rqgBADCMQg0AgGEUagAADIvqfdSa3nu5adMmkXXPDOHRpEkTkfft2ydy//79RaYvnXOqVKkisr7NofdI0YceekjM6e+rzoHQe263bt2a5ecCchpX1AAAGEahBgDAMAo1AACGRfU+6goVKoickpIi8uHDh0UuVapUyNeEa82aNUvkp59+WmR9njefJbDr8uXL7njBggU+v1Z/RmTy5MkZfq2+LeWOHTtEjqZbIiLycEUNAIBhFGoAAAyjUAMAYFhU96j1flu911KfS1ysWLGQrwkAAC+uqAEAMIxCDQCAYRRqAAAMi+oeNQAA1nFFDQCAYRRqAAAMo1ADAGAYhRoAAMMo1AAAGEahBgDAMAo1AACGUagBADCMQg0AgGEUagAADKNQAwBgGIUaAADDKNQAABhGoQYAwDAKNQAAhlGoAQAwjEINAIBhFGoAAAyjUAMAYBiFGgAAw/4Pl0XiurxH+dsAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 500x500 with 12 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "for k in range(12):\n",
    "    plt.subplot(3, 4, k+1)\n",
    "    plt.imshow(X_train[k], cmap='Greys')\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "8e085328-91f3-4034-a221-0a98ec1d37d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "f997e543-3625-4886-8f31-1169dde8e447",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(60000, 28*28).astype('float32') / 255\n",
    "X_valid = X_valid.reshape(10000, 28*28).astype('float32') / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "f0c0c44c-45d9-4a46-a395-14a4a6daaf8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 10\n",
    "y_train = to_categorical(y_train, n_classes)\n",
    "y_valid = to_categorical(y_valid, n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "9f332aaa-e767-4d5c-acb1-fca5c75c9481",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_valid[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "3c596592-0c82-4962-a75e-a13ae9d85e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# hidden layers\n",
    "model.add(Dense(64, activation='relu', input_shape=(784,)))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "\n",
    "# output layer\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "bc544842-b268-4c68-8807-cc7e84d6e381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_14 (Dense)            (None, 64)                50240     \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 55050 (215.04 KB)\n",
      "Trainable params: 55050 (215.04 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "89842fe5-dc8f-4147-8621-21dcbf2a83e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=SGD(learning_rate=0.01),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "73095902-63f2-4ad2-92e3-fe9f634bb1f6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 1.3963 - accuracy: 0.6037 - val_loss: 0.6732 - val_accuracy: 0.8427\n",
      "Epoch 2/20\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.5435 - accuracy: 0.8595 - val_loss: 0.4365 - val_accuracy: 0.8842\n",
      "Epoch 3/20\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 0.4218 - accuracy: 0.8831 - val_loss: 0.3761 - val_accuracy: 0.8973\n",
      "Epoch 4/20\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 0.3794 - accuracy: 0.8928 - val_loss: 0.3479 - val_accuracy: 0.9026\n",
      "Epoch 5/20\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 0.3572 - accuracy: 0.8993 - val_loss: 0.3307 - val_accuracy: 0.9076\n",
      "Epoch 6/20\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 0.3431 - accuracy: 0.9030 - val_loss: 0.3234 - val_accuracy: 0.9071\n",
      "Epoch 7/20\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.3333 - accuracy: 0.9051 - val_loss: 0.3135 - val_accuracy: 0.9142\n",
      "Epoch 8/20\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 0.3256 - accuracy: 0.9078 - val_loss: 0.3067 - val_accuracy: 0.9131\n",
      "Epoch 9/20\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.3198 - accuracy: 0.9090 - val_loss: 0.3045 - val_accuracy: 0.9134\n",
      "Epoch 10/20\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.3151 - accuracy: 0.9111 - val_loss: 0.2988 - val_accuracy: 0.9164\n",
      "Epoch 11/20\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.3110 - accuracy: 0.9128 - val_loss: 0.2995 - val_accuracy: 0.9165\n",
      "Epoch 12/20\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.3079 - accuracy: 0.9136 - val_loss: 0.2932 - val_accuracy: 0.9191\n",
      "Epoch 13/20\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.3047 - accuracy: 0.9140 - val_loss: 0.2935 - val_accuracy: 0.9186\n",
      "Epoch 14/20\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.3021 - accuracy: 0.9154 - val_loss: 0.2906 - val_accuracy: 0.9189\n",
      "Epoch 15/20\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.3002 - accuracy: 0.9161 - val_loss: 0.2897 - val_accuracy: 0.9195\n",
      "Epoch 16/20\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2981 - accuracy: 0.9162 - val_loss: 0.2872 - val_accuracy: 0.9209\n",
      "Epoch 17/20\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2962 - accuracy: 0.9168 - val_loss: 0.2866 - val_accuracy: 0.9210\n",
      "Epoch 18/20\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2946 - accuracy: 0.9178 - val_loss: 0.2859 - val_accuracy: 0.9198\n",
      "Epoch 19/20\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2930 - accuracy: 0.9179 - val_loss: 0.2853 - val_accuracy: 0.9191\n",
      "Epoch 20/20\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2917 - accuracy: 0.9182 - val_loss: 0.2824 - val_accuracy: 0.9210\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x404214c10>"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train,\n",
    "          batch_size=128,\n",
    "          epochs=20,\n",
    "          verbose=1,\n",
    "          validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695f2fd4-968d-4aa2-a892-1b0d0b2ee9a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b69016-706f-4966-be61-1cc7405f142b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
